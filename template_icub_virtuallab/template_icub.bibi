<?xml version="1.0" encoding="UTF-8"?>
<bibi xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns="http://schemas.humanbrainproject.eu/SP10/2014/BIBI" xsi:schemaLocation="http://schemas.humanbrainproject.eu/SP10/2014/BIBI ../bibi_configuration.xsd">
  <brainModel>
    <file>brain_model/idle_brain.py</file>
    <populations population="neurons" xsi:type="Range" from="0" to="2"/>
    <populations population="record" xsi:type="Range" from="0" to="2"/>
  </brainModel>
  <bodyModel>icub_model/model.sdf</bodyModel>
  <transferFunction xsi:type="PythonTransferFunction" src="csv_spike_monitor.py"/>
  <transferFunction xsi:type="PythonTransferFunction">
    #<![CDATA[
    import hbp_nrp_cle.tf_framework as nrp

    # This specifies that the neurons 0 to 2 of the circuit population
    # should be monitored. You can see them in the spike train widget
    @nrp.NeuronMonitor(nrp.brain.record, nrp.spike_recorder)
    def all_neurons_spike_monitor(t):
        # Uncomment to log into the 'log-console' visible in the simulation
        # clientLogger.info("Time: ", t)
        return True
    #]]>
  </transferFunction>

  <transferFunction xsi:type="PythonTransferFunction">
    #<![CDATA[
    import hbp_nrp_cle.tf_framework as nrp
    from hbp_nrp_cle.robotsim.RobotInterface import Topic
    import std_msgs.msg

    @nrp.MapSpikeSink("output_neuron", nrp.brain.neurons[1], nrp.leaky_integrator_alpha)
    @nrp.Neuron2Robot(Topic('/robot/eye_version/pos', std_msgs.msg.Float64))
    # Example TF: get output neuron voltage and output some value on robot actuator to change eyes position whever an output spike is detected. You could do something else with the voltage here and command the robot accordingly.
    def turn_eyes(t, output_neuron):
        data = 0.3
        if output_neuron.voltage < 0.0001:
            data = -0.3
        return std_msgs.msg.Float64(data)
    #]]>
  </transferFunction>

  <transferFunction xsi:type="PythonTransferFunction">
    #<![CDATA[
    import hbp_nrp_cle.tf_framework as nrp
    from hbp_nrp_cle.robotsim.RobotInterface import Topic
    import sensor_msgs.msg

    @nrp.MapRobotSubscriber("camera", Topic('/icub_model/left_eye_camera/image_raw', sensor_msgs.msg.Image))
    @nrp.MapSpikeSource("input_neuron", nrp.brain.neurons[0], nrp.poisson)
    @nrp.Robot2Neuron()
    # Example TF: get image and fire at constant rate. You could do something with the image here and fire accordingly.
    def grab_image(t, camera, input_neuron):
        image = camera.value
        input_neuron.rate = 10
    #]]>
  </transferFunction>

  <!-- temporary solution to forward all joints since the frontend only monitors /joint_states -->
  <transferFunction xsi:type="PythonTransferFunction">
    #<![CDATA[
    from sensor_msgs.msg import JointState

    @nrp.MapRobotSubscriber("joints", Topic("/robot/joints", JointState))
    @nrp.Neuron2Robot(Topic('/joint_states', JointState))
    def joint_states_passthrough(t, joints):
        return joints.value
    #]]>
  </transferFunction>

</bibi>
